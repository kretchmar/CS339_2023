{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTYPEo45CyOVo4CQPvO3xF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kretchmar/CS339_2023/blob/main/GloveExploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embeddings\n",
        "Matt Kretchmar <p>\n",
        "March 2023 <p>\n",
        "\n",
        "An exploration with the GLOVE model (similar to Word2Vec)"
      ],
      "metadata": {
        "id": "HxI-Q3lKIw3V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ssIWPq64IwgH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the Model\n",
        "Here we access the model and load it into memory."
      ],
      "metadata": {
        "id": "FR_x0Mz8LsfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = api.load('glove-wiki-gigaword-100')\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyXPsw7kJLSL",
        "outputId": "f6fcf4e6-58a1-42c9-be60-ee7053c68740"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==============================================----] 92.9% 119.0/128.1MB downloaded\n",
            "<gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7f8e844fee20>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word to Vector\n",
        "Here we can directly access the vector representation of any individual word"
      ],
      "metadata": {
        "id": "25CMp8xTLzI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model['king'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0opShCFuJkml",
        "outputId": "63263e6a-1851-4ff6-cad7-c65f9bb7faaa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.32307  -0.87616   0.21977   0.25268   0.22976   0.7388   -0.37954\n",
            " -0.35307  -0.84369  -1.1113   -0.30266   0.33178  -0.25113   0.30448\n",
            " -0.077491 -0.89815   0.092496 -1.1407   -0.58324   0.66869  -0.23122\n",
            " -0.95855   0.28262  -0.078848  0.75315   0.26584   0.3422   -0.33949\n",
            "  0.95608   0.065641  0.45747   0.39835   0.57965   0.39267  -0.21851\n",
            "  0.58795  -0.55999   0.63368  -0.043983 -0.68731  -0.37841   0.38026\n",
            "  0.61641  -0.88269  -0.12346  -0.37928  -0.38318   0.23868   0.6685\n",
            " -0.43321  -0.11065   0.081723  1.1569    0.78958  -0.21223  -2.3211\n",
            " -0.67806   0.44561   0.65707   0.1045    0.46217   0.19912   0.25802\n",
            "  0.057194  0.53443  -0.43133  -0.34311   0.59789  -0.58417   0.068995\n",
            "  0.23944  -0.85181   0.30379  -0.34177  -0.25746  -0.031101 -0.16285\n",
            "  0.45169  -0.91627   0.64521   0.73281  -0.22752   0.30226   0.044801\n",
            " -0.83741   0.55006  -0.52506  -1.7357    0.4751   -0.70487   0.056939\n",
            " -0.7132    0.089623  0.41394  -1.3363   -0.61915  -0.33089  -0.52881\n",
            "  0.16483  -0.98878 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Synonyms\n",
        "Here we can access \"similar\" words which are located nearby in vector space to a given word.  "
      ],
      "metadata": {
        "id": "UMmnnszwL50R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar('king')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcMkNBgVJqHq",
        "outputId": "05c43f02-d23e-4082-c9a8-2a29953e98a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('prince', 0.7682329416275024),\n",
              " ('queen', 0.7507690191268921),\n",
              " ('son', 0.7020887136459351),\n",
              " ('brother', 0.6985775232315063),\n",
              " ('monarch', 0.6977890729904175),\n",
              " ('throne', 0.6919990181922913),\n",
              " ('kingdom', 0.6811410188674927),\n",
              " ('father', 0.6802029013633728),\n",
              " ('emperor', 0.6712857484817505),\n",
              " ('ii', 0.6676074266433716)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar('banana')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf5hROtaJ8kL",
        "outputId": "a5419126-1194-4c84-a867-f70ba483909c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('coconut', 0.7097253799438477),\n",
              " ('mango', 0.7054824233055115),\n",
              " ('bananas', 0.6887733936309814),\n",
              " ('potato', 0.6629636287689209),\n",
              " ('pineapple', 0.6534532904624939),\n",
              " ('fruit', 0.6519855260848999),\n",
              " ('peanut', 0.6420576572418213),\n",
              " ('pecan', 0.6349173188209534),\n",
              " ('cashew', 0.6294420957565308),\n",
              " ('papaya', 0.6246591210365295)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine Similarity\n",
        "We can see from the code below that the model is using cosine similarity as a metric for finding similar words.   There must be some efficient search method (rather than linear search).  "
      ],
      "metadata": {
        "id": "57J2R4AJPiyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import norm\n",
        "def cosine_sim ( A, B ):\n",
        "    return np.dot(A,B) / ( norm(A)*norm(B) )"
      ],
      "metadata": {
        "id": "Jd6cePBPPUYq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sim(model['banana'],model['coconut'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8KQP-PEPWF3",
        "outputId": "7406a71e-3420-47c9-ce62-65fee3cfefb0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.70972526"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analogy\n",
        "We can use the most similar feature to do basic vector arithmetic"
      ],
      "metadata": {
        "id": "ynZyV69pPusD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar(positive=['woman','king'],negative=['man'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgOoVcWBKA4x",
        "outputId": "9aa79e7e-f3e7-486e-d215-aaaf16c12dba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7698541283607483),\n",
              " ('monarch', 0.6843380928039551),\n",
              " ('throne', 0.6755735874176025),\n",
              " ('daughter', 0.6594556570053101),\n",
              " ('princess', 0.6520534753799438),\n",
              " ('prince', 0.6517034769058228),\n",
              " ('elizabeth', 0.6464517712593079),\n",
              " ('mother', 0.6311717629432678),\n",
              " ('emperor', 0.6106470823287964),\n",
              " ('wife', 0.6098655462265015)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analogy(x1,x2,y1):\n",
        "  '''\n",
        "  x1 is to x2 as y1 is to y2\n",
        "  Returns the best answer for y2\n",
        "  '''\n",
        "  res = model.most_similar(positive=[y1,x2],negative=[x1])\n",
        "  return res[0][0]\n",
        "  "
      ],
      "metadata": {
        "id": "S2fx9QQzKTEH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analogy('man','king','woman')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ly6OuHN8Kukq",
        "outputId": "efd7d47f-948c-4ec6-f569-7a8d44ac205d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'queen'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analogy('dallas','usa','tokyo')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "foEB8DU8LFaG",
        "outputId": "7004bc0c-f4a4-49bf-e423-4fe0ca7e438b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'japan'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}